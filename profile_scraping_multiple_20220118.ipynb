{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read contest csv\n",
    "df = pd.read_csv('contest_data_2022-03-04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user id\n",
    "def get_user_id(df):\n",
    "\n",
    "    res = []\n",
    "    entries = df['entries']\n",
    "    for entry in entries:\n",
    "        res += re.findall(\"'participant_id': '\\d{5,8}'\", entry)\n",
    "\n",
    "\n",
    "    deleted_entries = df['deleted_entries']\n",
    "    for entry in deleted_entries:\n",
    "        res += re.findall(\"'participant_id': '\\d{5,8}'\", entry)\n",
    "\n",
    "    res = list(set(res))\n",
    "\n",
    "    # search participant ids\n",
    "    ids = list(map(lambda x: re.search(\"\\d{5,8}\", x).group(0), res))\n",
    "    return ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = get_user_id(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_scraping(user_id):\n",
    "\n",
    "    kv = {'user-agent': 'Mozilla/5.0'}\n",
    "    url = \"https://99designs.hk/profiles/\" + str(user_id) + \"/about\"\n",
    "    # url = \"https://99designs.hk/profiles/3923486/about\"\n",
    "    # print(url)\n",
    "\n",
    "    r = requests.get(url, headers=kv, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    r.status_code\n",
    "    r.encoding = r.apparent_encoding\n",
    "\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    ## user name\n",
    "    result = soup.find(name='h1', attrs='user-details__name')\n",
    "    user_name = result.text.strip()\n",
    "\n",
    "\n",
    "    ## about\n",
    "    result = soup.find(name='div', attrs='two-column-layout__body')\n",
    "    try:\n",
    "        about = result.find(name='p').text.strip()\n",
    "    except:\n",
    "        about = None\n",
    "\n",
    "\n",
    "    ## member since\n",
    "    result = soup.find(name='div', attrs='two-column-layout__body')\n",
    "    # country_and_member_since = result.findall(name='span', attrs='subtle-text')\n",
    "    country_and_member_since = result.find(name='div', attrs='section')\n",
    "    country_and_member_since = country_and_member_since.text.replace('\\n', '').strip()\n",
    "    # country_and_member_since\n",
    "    member_since = re.search('Member since:.+', country_and_member_since).group(0).split(':')[-1].strip()\n",
    "    \n",
    "    # stars and reviews\n",
    "    try:\n",
    "        stars_and_reviews = soup.find(name='div', attrs='aggregate-star-rating__description').text\n",
    "        stars = float(re.search('\\d\\.\\d{1,2} stars', stars_and_reviews).group(0).replace(\" stars\", \"\"))\n",
    "        review_count = int(re.search('\\d{1,3} reviews', stars_and_reviews).group(0).replace(\" reviews\", \"\"))\n",
    "    except:\n",
    "        stars = 0\n",
    "        review_count = 0\n",
    "\n",
    "    ## Experience：Contests won, Runner up, 1-to-1 Projects, Repeat clients, tags\n",
    "    result = soup.find(name='div', attrs='profile__tags')\n",
    "    experience = result.find(name='div', attrs='stats-panel').text.replace('\\n', '')\n",
    "    numbers = re.findall(' \\d+ ', experience)\n",
    "    contests_won = numbers[0]\n",
    "    runner_up = numbers[1]\n",
    "    one_to_one_projects = numbers[2]\n",
    "    repeat_clients = numbers[3]\n",
    "\n",
    "\n",
    "    ## tags\n",
    "    result = soup.find(name='div', attrs='profile__tags')\n",
    "    result = result.find(name='div', attrs='pill-group').text.replace('\\n', ' ')\n",
    "    tags = result.strip().split('     ')\n",
    "\n",
    "\n",
    "    ## certification\n",
    "    result = soup.find_all(name='div', attrs='profile__tag-section')[1]\n",
    "    certification = result.find(name='div', attrs='pill-group').text.replace('\\n', '').strip().split('                                                              ')\n",
    "    \n",
    "\n",
    "    ## reviews\n",
    "    results = soup.find_all(name='em')\n",
    "    reviews = []\n",
    "    for result in results:\n",
    "        reviews.append(result.text.replace('\\n', '').strip().replace('\"', ''))\n",
    "\n",
    "\n",
    "    data = {'user_id': user_id, 'user_name': user_name, 'about': about, \n",
    "            'stars': stars, 'review_count': review_count,\n",
    "            'member_since': member_since, 'contests_won': contests_won, \n",
    "            'runner_up': runner_up, '1_to_1_projects': one_to_one_projects, \n",
    "            'tags': tags,\n",
    "            'repeat_clients': repeat_clients, 'reviews': reviews, \n",
    "            'certification': certification,\n",
    "            'timestamp': str(datetime.now().date())}\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [1:21:22<00:00,  4.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "result = []\n",
    "\n",
    "for id in tqdm(user_ids):\n",
    "    try:\n",
    "        data = multiple_scraping(id)\n",
    "        if data: \n",
    "            result.append(data)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile_df.to_csv('user_profile_2022-03-04.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1175632',\n",
       " '2554953',\n",
       " '281850',\n",
       " '3250438',\n",
       " '3610951',\n",
       " '3800798',\n",
       " '4859999',\n",
       " '4866302',\n",
       " '4953165',\n",
       " '4968310',\n",
       " '901345'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(user_ids).difference(user_profile_df['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5af03e6f6884cdcbf495aa98cbd8d63d5d0ed05506dbd026ba0a4981213ae30b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
